# Statistics analysis

```{julia}
import Pkg
Pkg.activate("docs")
using DmspElfinConjunction, DMSP
using Dates
using TimeseriesUtilities
using DimensionalData, DataFrames, DataFramesMeta
using GeoCotrans, IRBEM
using SPEDAS
using Accessors
using AlgebraOfGraphics
using CairoMakie, GLMakie
using StatsBase
using CategoricalArrays
using Beforerr: easy_save

set_aog_theme!()

includet("../src/plot.jl")
includet("../src/workload.jl")
includet("../src/mechanisms.jl")
includet("../src/statplot.jl")
includet("../src/demo.jl")
```


```{julia}
# tr = Date("2020-07-01"), Date("2020-12-01")
tr = Date("2020-01-01"), Date("2022-08-01")
# rm("docs/data/ELFIN=a_t0=2022-07-01_t1=2022-08-01_ids=16-17-18.jld2")
ids = 16:18
df_a = produce(tsplit(tr, Month), "a", ids)
df_b = produce(tsplit(tr, Month), "b", ids)
df = vcat(df_a, df_b)

unique(df.mechanism), counts(Int.(df.mechanism))
```

```{julia}
using SpectralModels: A, κ, E_c, n_flux, e_flux

γ_len = @optic _.γ
const m1 = @optic _.model1
const m2 = @optic _.model2
const Emin = @optic _.Emin

function parameters(df)
    @transform(df,
        :log_A1 = (log10 ∘ A ∘ m1).(:model),
        :E_c1 = (E_c ∘ m1).(:model),
        :γ = (γ_len ∘ m1).(:model),
        :log_A2 = (log10 ∘ A ∘ m2).(:model),
        :E_c2 = (E_c ∘ m2).(:model),
        :κ = (κ ∘ m2).(:model),
        :Emin = Emin.(:model),
        :mlat, :maxAE, :mlt_elx, :mlt_dmsp
    )
end

tdf = let df = df, rev = false
    qs = (x -> round.(quantile(skipmissing(x), [0.02, 0.1, 0.9, 0.98]), sigdigits=2)) => :quantiles
    vals = A.(m1.(df.model))
    @info describe(parameters(df), :mean, qs, :q25, :median, :q75, :nmissing)
    perm = sortperm(vals; rev=rev)
    df[perm, :]
end

sdf = let Emin = 0.03
    @chain parameters(df) begin
        @rsubset!(20 > :κ > 1, :E_c1 < 20, :E_c2 < 20, abs(:γ) < 20, 0 < :log_A1 < 30, 0 < :log_A2 < 20)
        @transform(
            :J1 = (n_flux(Emin, 100) ∘ m1).(:model),
            :J2 = (n_flux(Emin, 1000) ∘ m2).(:model),
            :JE1 = (e_flux(Emin, 100) ∘ m1).(:model),
            :JE2 = (e_flux(Emin, 1000) ∘ m2).(:model),
            :JE_e10 = (e_flux(10, 1000) ∘ m2).(:model) .+ (e_flux(10, 1000) ∘ m1).(:model),
        )
    end
end

size(sdf, 1) # 27759
```

## Check some events

```{julia}
begin
    row = tdf[2, :]
    probe = "a"
    trange = extend(row.trange_elx, Minute(4))
    elx_mlt_trange = extend(trange, Second(1)) # Extend a bit to cover flux time range
    @info trange row.mlat
    elx_flux = permutedims(ELFIN.epd(trange, probe))
    elx_gei = ELFIN.gei(elx_mlt_trange, probe)
    elx_mlt, elx_mlat = gei2mlt_mlat(tview(elx_gei, elx_mlt_trange))

    dmsp_mlt, dmsp_mlat = get_mlt_mlat(row.id, trange)
    dmsp_flux = DMSP.flux(trange, row.id)

    df = workload(trange, (row.id,), elx_flux, elx_gei)
    mlats = nothing
    # mlats = [61, 64]
    # mlats = -66:0.5:-65

    # quicklook(trange, elx_flux, elx_mlt, elx_mlat, dmsp_flux, dmsp_mlt, dmsp_mlat)
    demo_plot(trange, df, elx_flux, elx_mlt, elx_mlat, dmsp_flux, dmsp_mlt, dmsp_mlat; mlats)
end
``` 

## Dependence analysis

```{julia}
using Statistics

vars = [:log_A1 => "Log A (ExpPow)", :E_c1 => "E_c (ExpPow)", :γ => "γ (ExpPow)", :Emin => "Transition Energy", :log_A2 => "Log A (Kappa)", :E_c2 => "E_c (Kappa)", :κ => "κ (Kappa)"]

# Prepare data with MLT and MLAT binning
mlat_binedges = 55:1:80
mlt_binedges = 0.0:2.0:24.0
ae_binedges = [0, 100, 300]

function mlt_round(x, d)
    r = round(Int, x)
    r == 24 ? 0 : r
end

fmt(from, to, i; leftclosed, rightclosed) = string(from + (to - from) / 2)
_mlat(s) = parse(Float64, String(s))
mlt_fmt(from, to, i; leftclosed, rightclosed) = string(Int(from + (to - from) / 2))
mlt_levels = ["13", "15", "17", "19", "21", "23", "1", "3", "5", "7", "9", "11"]

make_gdf(df) = @chain df begin
    @transform(
        :maxAE_bin = cut(:maxAE, ae_binedges; extend=true),
        :mlt_bin = cut(:mlt_elx, mlt_binedges; extend=missing, labels=mlt_fmt),
        # :mlt_bin = mlt_round.(:mlt_elx),
        :mlat_bin = cut(abs.(:mlat), mlat_binedges; extend=missing, labels=fmt),
    )
    @groupby(:mlt_bin, :mlat_bin, :maxAE_bin)
end

gdf = make_gdf(sdf)
```

### MLT, maxAE space

```{julia}
tdf = let binedges_ae = [0, 100, 300], binedges_mlt = 0:2:24
    @chain sdf begin
        @transform(
            :maxAE_bin = cut(:maxAE, binedges_ae; extend=true),
            :mlt_bin = cut(:mlt_elx, binedges_mlt; extend=missing, labels=mlt_fmt),
        )
        @groupby(:mlt_bin, :maxAE_bin)
        combine(_variable.(vars) .=> mean, renamecols=false)
        dropmissing!
    end
end

# Reorder MLT levels: 12→24, then 0→12
levels!(tdf.mlt_bin, mlt_levels)

#  plot in such a way, that it will be MLT from 12 to 24, and then from 0 to 12, so 24=0 will be in the middle of figure
f = Figure(; size=(600, 600))
base_plt = data(tdf) * mapping(:mlt_bin => "MLT", :maxAE_bin => "AE") * visual(Heatmap)
layouts = [(1, 1), (2, 1), (3, 1), (1, 2), (2, 2), (3, 2)]
foreach(layouts, vars) do (i, j), var
    gl = GridLayout(f[i, j])
    sf = draw!(gl[2, 1], base_plt * mapping(var))
    colorbar!(gl[1, 1], sf; vertical=:false)
    i != 3 && hidexdecorations!(sf[1].axis)
    j != 1 && hideydecorations!(sf[1].axis)
    rowgap!(gl, 4)
end
easy_save("params_mlt_ae_mean")
```

## MLT, MLAT space, separately for three MaxAE ranges

```{julia}
tdf_spatial = combine(gdf, nrow => :n, renamecols=false) |> dropmissing!
levels!(tdf_spatial.mlt_bin, mlt_levels)
plt = data(tdf_spatial) * mapping(:mlt_bin => "MLT", :mlat_bin => "MLAT", :n) * visual(Heatmap) * mapping(col=:maxAE_bin)
fg = draw(plt; figure=(; size=(1000, 300)))
orig_yticks = fg.grid[1].axis.yticks[]
# do not print odd numbers
fg.grid[1].axis.yticks[] = orig_yticks[1][2:2:end], orig_yticks[2][2:2:end]
easy_save("n_mlt_mlat")
```

### Model parameters variation

```{julia}
f = Figure(; size=(1500, 700))
tdf_spatial = combine(gdf, _variable.(vars) .=> mean, renamecols=false) |> dropmissing!
plot_params_variation(f, tdf_spatial, vars)
easy_save("params_mlt_mlat_mean")

f = Figure(; size=(1500, 700))
tdf_spatial = combine(gdf, _variable.(vars) .=> median, renamecols=false) |> dropmissing!
plot_params_variation(f, tdf_spatial, vars)
easy_save("params_mlt_mlat_median")
```

![](../figures/params_mlt_mlat_mean.png) See also [params_mlt_mlat_median.png](../figures/params_mlt_mlat_median.png)

### Total number flux and energy flux variation

```{julia}
J_vars = [:J1 => "(a) Number flux (ExpPow)", :J2 => "(b) Number flux (Kappa)", :JE1 => "(c) Energy flux (ExpPow)", :JE2 => "(d) Energy flux (Kappa)", :JE_e10 => "(e) Energy flux (E>10 keV)"]
let vars = J_vars
    f = Figure(; size=(1200, 700))
    df = combine(gdf, _variable.(vars) .=> mean, renamecols=false) |> dropmissing!
    plot_params_variation(f, df, vars; colorranges=(; JE1=(1e10, 2.6e11), JE2=(1e10, 2.6e11), JE_e10=(1e10, 2.6e11)))
    easy_save("flux_mlt_mlat")
end
```

![](../figures/flux_mlt_mlat.png)

Effects of different mechanisms on the fluxes result

```{julia}
for (key, mdf) in pairs(groupby(sdf, :mechanism))
    let gdf = make_gdf(mdf), vars = J_vars
        f = Figure(; size=(1200, 700))
        df = combine(gdf, _variable.(vars) .=> mean, renamecols=false) |> dropmissing!
        plot_params_variation(f, df, vars; colorranges=(; JE1=(1e10, 2.6e11), JE2=(1e10, 2.6e11), JE_e10=(1e10, 2.6e11)))
        easy_save("flux_mlt_mlat_$(key.mechanism)"; force=true)
    end
end
```

####

Since in fitting, the parameters are not independent, we check the most probable values of parameter for each models.

```{julia}
using FHist

model1s = m1.(df.model)
model2s = m2.(df.model)

function auto_bins(ary; nbins=nothing)
    nbins = @something nbins FHist._sturges(ary)
    lo, hi = quantile(ary, [0.05, 0.95])
    StatsBase.histrange(lo, hi, nbins)
end

@inline function HistFunc(n)
    @assert n in (1, 2, 3)
    n == 1 && return Hist1D
    n == 2 && return Hist2D
    n == 3 && return Hist3D
end

function most_likely_params(arrs...)
    binedges = auto_bins.(arrs)
    h = HistFunc(length(arrs))(arrs; binedges)
    idxs = argmax(h.bincounts)
    getindex.(h.binedges, Tuple(idxs))
end

function most_likely_params(df, vars)
    arrs = getproperty.(Ref(df), vars)
    most_likely_params(arrs...)
end

most_likely_params(sdf, (:log_A2, :E_c2, :κ))

tdf_most_likely = let
    @chain sdf begin
        @transform(
            :maxAE_bin = cut(:maxAE, ae_binedges; extend=true),
            :mlt_bin = cut(:mlt_elx, mlt_binedges; extend=missing, labels=mlt_fmt),
            :mlat_bin = cut(abs.(:mlat), mlat_binedges; extend=missing, labels=fmt),
        )
        @groupby(:mlt_bin, :mlat_bin, :maxAE_bin)
        combine(
            [:log_A1, :E_c1, :γ] => most_likely_params => :model1,
            [:log_A2, :E_c2, :κ] => most_likely_params => :model2,
            :Emin => most_likely_params => :Emin,
        )
        @rtransform(
            :Emin = :Emin[1],
            :log_A1 = :model1[1],
            :E_c1 = :model1[2],
            :γ = :model1[3],
            :log_A2 = :model2[1],
            :E_c2 = :model2[2],
            :κ = :model2[3],
        )
        dropmissing!
    end
end

# plot_params_variation(f, tdf_most_likely, vars)
# easy_save("params_mlt_mlat_most_likely")
```

![](../figures/params_mlt_mlat_most_likely.png)


### Fitting of probability distributions

#### Empirical pdf for `log_A1`

```{julia}
using StatsBase
using FHist
includet("../src/statmodel.jl")
# logA1_empirical = empirical_conditional_density(sdf, :log_A1)
var_edges = map(vars) do var
    edge_min, edge_max = quantile(sdf[!, var], [0.01, 0.99])
    range(edge_min, edge_max; length=31)
end

_maximum(h) = maximum(h.weights)
_maximum(h::Hist1D) = maximum(h.bincounts)

hist_funcs = HistFunc.(var_edges)

tdf = let mlat_binedges = 49:2:81
    @chain sdf begin
        @transform(
            :maxAE_bin = cut(:maxAE, ae_binedges; extend=true),
            :mlt_bin = cut(:mlt_elx, mlt_binedges; extend=missing, labels=mlt_fmt),
            :mlat_bin = cut(abs.(:mlat), mlat_binedges; extend=missing, labels=fmt),
        )
        @groupby(:mlt_bin, :mlat_bin, :maxAE_bin)
        combine(vars .=> hist_funcs, renamecols=false)
        dropmissing!
    end
end
# ae_levels = levels(tdf.maxAE_bin)
mlt_levels = levels(tdf.mlt_bin)
```

#### Visualizing the empirical pdf

```{julia}
f = Figure(size=(1200, 900))

mlt_idxs = 1:2:12

plot_empirical_conditional_density(f, tdf, vars; mlt_idxs)
# easy_save("empirical_pdf")
f
```

![](../figures/empirical_pdf.png)



```{julia}
using Measurements

# Fix for AlgebraOfGraphics
# Base.typemin(x::Type{Measurement{Float64}}) = -Inf
# Base.typemax(x::Type{Measurement{Float64}}) = Inf

mean_std(x) = mean(x) ± std(x)

let binedges = 5:15:200
    tdf = @chain sdf begin
        @transform(:maxAE_bin = cut(:maxAE, binedges; extend=missing))
        @groupby(:maxAE_bin)
        combine(vars .=> mean_std, :maxAE => mean; renamecols=false)
        dropmissing!
    end

    # https://github.com/MakieOrg/AlgebraOfGraphics.jl/issues/688
    # AoG does not support Errorbars
    # plt = data(tdf) * mapping(:maxAE, [:log_A1, :E_c1, :γ, :log_A2, :E_c2, :κ]) *
    #   (visual(Scatter) + visual(Errorbars, whiskerwidth=8)) * mapping(layout=AoG.dims(1))
    # draw(plt)

    f = Figure()
    x = tdf.maxAE
    ys = vars .=> ["log A1", "E_c (keV)", "γ", "Emin", "log A2", "E_c2 (keV)", "κ"]
    layouts = [(1, 1), (2, 1), (3, 1), (4, 1), (1, 2), (2, 2), (3, 2)]

    axs = map(layouts, ys) do (i, j), (var, ylabel)
        ax = Axis(f[i, j]; ylabel)
        y = tdf[!, var]
        scatter!(ax, x, y)
        errorbars!(ax, x, y, whiskerwidth=8)
        i != 3 && hidexdecorations!(ax)
        ax
    end
    f
end
```

#### Parametric pdf model conditioned on (MLAT, MLT)

Fitted a cyclic linear model for the conditional mean and log-variance plus a Normal pdf evaluator, then compared model vs empirical densities with RMSE/KL metrics and slice-by-slice line plots.

- The design matrix X includes a constant, |MLAT|, |MLAT|^2, and diurnal harmonics cos(θ), sin(θ) plus their interactions with |MLAT|, where θ = 2π·MLT/24. Solving X \ log_A1 gives β coefficients that predict the conditional mean μ(mlat, mlt).
    - Mean surface: with θ = 2π·(MLT mod 24)/24 and m = |MLAT|, the model sets $μ(m, θ) = β₀ + β₁ m + β₂ m² + β₃ cos θ + β₄ sin θ + β₅ m cos θ + β₆ m sin θ$. The coefficients β are found by least squares: β = argmin‖Xβ - log_A1‖², where the rows of X contain the seven basis functions above.
- Residuals from that mean fit are used to model heteroscedasticity. Another matrix Z (constant, |MLAT|, |MLAT|^2, cos, sin) regresses log(residual^2 + ε) to estimate a log-variance surface γ, keeping the variance positive via the exponential transform.
    - Variance surface: residuals r = log_A1 - μ̂ are used to fit $log σ²(m, θ) = γ₀ + γ₁ m + γ₂ m² + γ₃ cos θ + γ₄ sin θ$, with γ estimated via least squares on the features matrix Z. The model enforces positivity by taking $σ(m, θ) = √(exp(log σ²))$.
- Given μ and σ derived from β and γ, the code assumes a Gaussian conditional density: `pdf_logA1_model(P, mlat, mlt)` evaluates the Normal pdf with those parameter
    - Conditional pdf (notebooks/stats.qmd:341–353): assuming log_A1 | m, θ ∼ Normal(μ(m, θ), σ²(m, θ)), the fitted density evaluates as $pdf(P | m, θ) = (1 / (σ √(2π))) · exp[ -½ ((P - μ)/σ)² ]$.

```{julia}
using LinearAlgebra

# 2π * :elfin_mlt / 24

emp = logA1_empirical
emp.df.angle .= @. 2π * emp.df.elfin_mlt / 24
θ = emp.df.angle
abs_mlat_vals = emp.df.abs_mlat

X = hcat(
    ones(size(emp.df, 1)),
    abs_mlat_vals,
    abs_mlat_vals .^ 2,
    cos.(θ),
    sin.(θ),
    abs_mlat_vals .* cos.(θ),
    abs_mlat_vals .* sin.(θ),
)
β_logA1 = X \ emp.df.log_A1
μ_hat = X * β_logA1
residuals = emp.df.log_A1 .- μ_hat

Z = hcat(
    ones(size(emp.df, 1)),
    abs_mlat_vals,
    abs_mlat_vals .^ 2,
    cos.(θ),
    sin.(θ),
)
γ_logA1 = Z \ log.(residuals .^ 2 .+ 1e-6)

predict_logA1(mlat, mlt) = begin
    abs_mlat = abs(mlat)
    φ = 2π * mod(mlt, 24) / 24
    cosφ, sinφ = cos(φ), sin(φ)
    μ = dot(β_logA1, (1.0, abs_mlat, abs_mlat^2, cosφ, sinφ, abs_mlat * cosφ, abs_mlat * sinφ))
    logσ2 = dot(γ_logA1, (1.0, abs_mlat, abs_mlat^2, cosφ, sinφ))
    σ = sqrt(exp(logσ2))
    σ = max(σ, 1e-3)
    return μ, σ
end

pdf_logA1_model(P, mlat, mlt) = begin
    μ, σ = predict_logA1(mlat, mlt)
    coeff = 1 / (σ * sqrt(2π))
    expo = -0.5 * ((P - μ) / σ)^2
    return coeff * exp(expo)
end

model_density = similar(emp.cond_density)
@views for j in axes(model_density, 2), k in axes(model_density, 3)
    mlat = emp.mlat_centers[j]
    mlt = emp.mlt_centers[k]
    model_density[:, j, k] .= pdf_logA1_model.(emp.p_centers, Ref(mlat), Ref(mlt))
end

logA1_model = (; β_logA1, γ_logA1, model_density, predict_logA1, pdf_logA1_model)
logA1_model
```

#### Model evaluation

```{julia}
emp = logA1_empirical
model = logA1_model

widths_P = emp.widths_P
diff_density = model.model_density .- emp.cond_density
rmse = sqrt(mean(diff_density .^ 2))
mae = mean(abs.(diff_density))

eps = 1e-9
kl = Matrix{Float64}(undef, length(emp.mlat_centers), length(emp.mlt_centers))
fill!(kl, NaN)
@views for j in axes(emp.cond_density, 2), k in axes(emp.cond_density, 3)
    p = emp.cond_density[:, j, k]
    q = model.model_density[:, j, k]
    mask = p .> 0
    if any(mask)
        kl[j, k] = sum(p[mask] .* (log.(p[mask] .+ eps) .- log.(q[mask] .+ eps)) .* widths_P[mask])
    end
end

println("RMSE across pdf grid = $(round(rmse, digits=4))")
println("Mean absolute difference = $(round(mae, digits=4))")
println("Median KL divergence (per bin) = $(round(median(skipmissing(vec(kl))), digits=4))")

comparison_mlat = [60.0, 65.0, 70.0]
comparison_mlt = [0.0, 12.0, 18.0]

index_of(values, target) = findmin(abs.(values .- target))[2]

f = Figure(size=(900, 720))
for (i, mlat_target) in enumerate(comparison_mlat)
    mlat_idx = index_of(emp.mlat_centers, mlat_target)
    for (j, mlt_target) in enumerate(comparison_mlt)
        mlt_idx = index_of(emp.mlt_centers, mlt_target)
        ax = Axis(
            f[i, j];
            title="|MLAT| ~ $(round(emp.mlat_centers[mlat_idx], digits=1)) deg, MLT ~ $(round(emp.mlt_centers[mlt_idx], digits=1)) h",
            xlabel="log10(A1)",
            ylabel=i == length(comparison_mlat) ? "pdf" : "",
            yscale=log10
        )
        empirical = emp.cond_density[:, mlat_idx, mlt_idx]
        modeled = model.model_density[:, mlat_idx, mlt_idx]
        lines_emp = lines!(ax, emp.p_centers, empirical; color=:steelblue, linewidth=2)
        lines_mod = lines!(ax, emp.p_centers, modeled; color=:orange, linestyle=:dash, linewidth=2)
        ylims!(ax, (1e-6, 1))
        i != length(comparison_mlat) && hidexdecorations!(ax)
        j != 1 && hideydecorations!(ax)
        if i == 1 && j == 1
            axislegend(ax, [lines_emp, lines_mod], ["Empirical", "Model"]; position=:rt)
        end
    end
end
f
```




### Joint probability distributions

Probability distributions of observations in (Mlat, Ec) and (Mlat, gamma) spaces?

```{julia}
includet("../src/statplot.jl")
using PairPlots, AlgebraOfGraphics
using StatsBase
const AoG = AlgebraOfGraphics

E_c1(model) = E_c(m1_len(model))
E_c2(model) = E_c(m2_len(model))

# plot_parameter_distributions_aog(df; normalization=:pdf)
# plot_parameter_distributions_aog(df; normalization=:column)

# plot_parameter_distributions_aog(df, :mlat; normalization=:column)
plot_parameter_distributions_aog(dropmissing(df), :maxAE; normalization=:pdf, x_binedges=(0:20:400))
# plot_parameter_distributions_aog(dropmissing(df), :maxAE; normalization=:column, x_binedges=(0:20:1000))

```

```{julia}
# Use PairPlots for comprehensive parameter analysis
function plot_parameter_pairplots(df)
    # Create analysis DataFrame with all relevant parameters
    plot_df = DataFrame(
        mlat=df.mlat,
        E_c=E_c.(m1_len.(df.model)),
        γ=γ_len.(m1_len.(df.model)),
        κ=κ_len.(m2_len.(df.model)),
        success=df.success,
        Δmlt=df.Δmlt
    )

    # Filter for successful fits
    successful_df = @subset(plot_df, :success)

    if nrow(successful_df) == 0
        println("No successful fits found for plotting")
        return nothing
    end

    # Create comprehensive pair plot with all parameters
    return pairplot(successful_df[:, [:mlat, :E_c, :γ, :κ, :Δmlt]])
end

# Plot comprehensive pairwise analysis
plot_parameter_pairplots(df)
```

```{julia}
# Advanced AlgebraOfGraphics visualization with faceting and grouping
function plot_advanced_parameter_analysis(df)
    # Create comprehensive analysis DataFrame
    plot_df = DataFrame(
        mlat=df.mlat,
        E_c=E_c.(m1_len.(df.model)),
        γ=γ_len.(m1_len.(df.model)),
        κ=κ_len.(m2_len.(df.model)),
        success=df.success,
        Δmlt=df.Δmlt,
        id=df.id,
        # Create MLAT bins for grouping
        mlat_bin=cut(df.mlat, 5, labels=["High", "Mid-High", "Mid", "Mid-Low", "Low"])
    )

    # Filter for successful fits
    successful_df = @subset(plot_df, :success)

    if nrow(successful_df) == 0
        println("No successful fits found for plotting")
        return nothing
    end

    # Create multi-faceted analysis
    base = data(successful_df)

    # Density plots with grouping by DMSP satellite ID
    density_analysis = base *
                       mapping(:mlat => "MLAT (degrees)", :E_c => "E_c (keV)",
                           color=:id => nonnumeric, layout=:id => nonnumeric) *
                       (density() * visual(alpha=0.7) +
                        smooth() * visual(linewidth=2))

    # Scatter plot with trend analysis
    scatter_analysis = base *
                       mapping(:γ => "γ", :E_c => "E_c (keV)",
                           color=:mlat_bin => "MLAT Region",
                           markersize=:Δmlt => "ΔMLT") *
                       (visual(Scatter, alpha=0.7) +
                        smooth() * visual(linewidth=1.5))

    # Create figure with multiple panels
    f = Figure(size=(1600, 1000))

    # Panel 1: Density analysis by satellite
    draw!(f[1, :], density_analysis;
        axis=(title="E_c vs MLAT by DMSP Satellite",
            subtitle="Density distributions with trend lines"))

    # Panel 2: Parameter correlation analysis  
    draw!(f[2, 1], scatter_analysis;
        axis=(title="Parameter Correlations",
            subtitle="E_c vs γ colored by MLAT region, sized by ΔMLT"))

    # Panel 3: Distribution summary
    hist_plot = base *
                mapping(:E_c => "E_c (keV)", layout=:mlat_bin => nonnumeric) *
                histogram(bins=15) * visual(alpha=0.8, color=:steelblue)

    draw!(f[2, 2], hist_plot;
        axis=(title="E_c Distribution by MLAT Region",))

    return f
end

# Create advanced multi-panel analysis
plot_advanced_parameter_analysis(df)
```

```{julia}
# Statistical summary of the distributions
function summarize_parameter_distributions(df)
    successful_df = @subset(df, :success)

    println("=== Parameter Distribution Summary ===")
    println("Total successful fits: $(nrow(successful_df))")
    println("Total observations: $(nrow(df))")
    println("Success rate: $(round(nrow(successful_df)/nrow(df)*100, digits=2))%")
    println()

    # MLAT statistics
    println("MLAT Statistics:")
    println("  Range: $(round(minimum(successful_df.mlat), digits=2))° to $(round(maximum(successful_df.mlat), digits=2))°")
    println("  Mean: $(round(mean(successful_df.mlat), digits=2))°")
    println("  Std: $(round(std(successful_df.mlat), digits=2))°")
    println()

    # E_c statistics
    E_c_values = [row.model2.E_c for row in eachrow(successful_df) if haskey(row.model2, :E_c)]
    if !isempty(E_c_values)
        println("E_c Statistics:")
        println("  Range: $(round(minimum(E_c_values), digits=2)) to $(round(maximum(E_c_values), digits=2)) keV")
        println("  Mean: $(round(mean(E_c_values), digits=2)) keV")
        println("  Std: $(round(std(E_c_values), digits=2)) keV")
        println("  Median: $(round(median(E_c_values), digits=2)) keV")
        println()
    end

    # γ statistics
    gamma_values = [row.model1.γ for row in eachrow(successful_df) if haskey(row.model1, :γ)]
    if !isempty(gamma_values)
        println("γ Statistics:")
        println("  Range: $(round(minimum(gamma_values), digits=2)) to $(round(maximum(gamma_values), digits=2))")
        println("  Mean: $(round(mean(gamma_values), digits=2))")
        println("  Std: $(round(std(gamma_values), digits=2))")
        println("  Median: $(round(median(gamma_values), digits=2))")
    end
end

# Print statistical summary
summarize_parameter_distributions(df)
```








## Parameter Statistics and Correlations

```julia
#TODO: update this part
# Calculate parameter statistics and correlations
using Statistics

# Create summary statistics
param_stats = (
    plec_A_mean=mean([p.plec_A for p in param_analysis]),
    plec_A_std=std([p.plec_A for p in param_analysis]),
    plec_γ_mean=mean([p.plec_γ for p in param_analysis]),
    plec_γ_std=std([p.plec_γ for p in param_analysis]),
    plec_E_c_mean=mean([p.plec_E_c for p in param_analysis]),
    plec_E_c_std=std([p.plec_E_c for p in param_analysis]),
    sbpl_A_mean=mean([p.sbpl_A for p in param_analysis]),
    sbpl_A_std=std([p.sbpl_A for p in param_analysis]),
    sbpl_γ1_mean=mean([p.sbpl_γ1 for p in param_analysis]),
    sbpl_γ1_std=std([p.sbpl_γ1 for p in param_analysis]),
    sbpl_γ2_mean=mean([p.sbpl_γ2 for p in param_analysis]),
    sbpl_γ2_std=std([p.sbpl_γ2 for p in param_analysis]),
    sbpl_Eb_mean=mean([p.sbpl_Eb for p in param_analysis]),
    sbpl_Eb_std=std([p.sbpl_Eb for p in param_analysis])
)

@info "Parameter Statistics:" param_stats

# Create correlation plot between key parameters
f_corr = Figure(size=(1200, 900))

# PowerLawExpCutoff γ vs E_c
ax_corr1 = Axis(f_corr[1, 1], xlabel="Power Index γ (PowerLawExpCutoff)",
    ylabel="Cutoff Energy E_c (keV)", yscale=log10,
    title="PowerLawExpCutoff: γ vs E_c")
scatter!(ax_corr1, [p.plec_γ for p in param_analysis],
    [p.plec_E_c for p in param_analysis],
    color=mlats_all, colormap=:viridis, markersize=8)

# PowerLawExpCutoff A vs γ  
ax_corr2 = Axis(f_corr[1, 2], xlabel="Amplitude A (PowerLawExpCutoff)",
    ylabel="Power Index γ", xscale=log10,
    title="PowerLawExpCutoff: A vs γ")
scatter!(ax_corr2, [p.plec_A for p in param_analysis],
    [p.plec_γ for p in param_analysis],
    color=mlats_all, colormap=:viridis, markersize=8)

# SmoothBrokenPowerlaw γ1 vs γ2
ax_corr3 = Axis(f_corr[2, 1], xlabel="Power Index γ₁ (SBPL)",
    ylabel="Power Index γ₂ (SBPL)",
    title="SmoothBrokenPowerlaw: γ₁ vs γ₂")
scatter!(ax_corr3, [p.sbpl_γ1 for p in param_analysis],
    [p.sbpl_γ2 for p in param_analysis],
    color=mlats_all, colormap=:viridis, markersize=8)

# Break energy vs MLAT colored by PowerLawExpCutoff cutoff
ax_corr4 = Axis(f_corr[2, 2], xlabel="MLAT", ylabel="Break Energy Eb (keV)",
    yscale=log10, title="Break Energy vs MLAT")
scatter!(ax_corr4, mlats_all, [p.sbpl_Eb for p in param_analysis],
    color=[p.plec_E_c for p in param_analysis], colormap=:plasma, markersize=8)

# Add colorbars
Colorbar(f_corr[1:2, 3], colormap=:viridis, colorrange=extrema(mlats_all),
    label="MLAT")

f_corr
```
