# Statistics analysis

```{julia}
import Pkg
Pkg.activate("docs")
using DmspElfinConjunction, DMSP, ELFIN
using Dates
using TimeseriesUtilities
using DimensionalData, DataFrames, DataFramesMeta
using GeoCotrans, IRBEM
using SPEDAS
using Accessors
using AlgebraOfGraphics
using Beforerr
using CairoMakie, GLMakie

set_aog_theme!()

includet("../src/plot.jl")
includet("../src/workload.jl")
```


```{julia}
tr = Date("2020-01-01"), Date("2022-08-01")
ids = 16:18
df_a = produce(tsplit(tr, Month), "a", ids)
df_b = produce(tsplit(tr, Month), "b", ids)
df = vcat(df_a, df_b)
```


```{julia}
using DmspElfinConjunction: A

γ_len = @optic _.γ
κ_len = @optic _.κ
const m1 = @optic _.model1
const m2 = @optic _.model2
```

TODO: investigate 1. why some E_c are so large 2. why some κ are so large and some are negative


```{julia}
f = Figure()
sdf = @chain df begin
    @rtransform(:E_c = E_c(m1(:model)))
    sort(:E_c; rev=true)
end
ax = plot_spectra(f[1, 1], sdf[1:3, :])
# ylims!(ax, 1.0e1, 1.0e12)
# axislegend(ax; position=:lb)
f
```

## Dependence analysis

```{julia}
using Statistics

sdf = @chain df begin
    @transform(
        :log_A1 = (log10 ∘ A ∘ m1).(:model),
        :E_c1 = (E_c ∘ m1).(:model),
        :γ = (γ_len ∘ m1).(:model),
        :log_A2 = (log10 ∘ A ∘ m2).(:model),
        :E_c2 = (E_c ∘ m2).(:model),
        :κ = (κ_len ∘ m2).(:model),
    )
    # TODO: remove this subset by improving the model
    @rsubset!(20 > :κ > 0, :E_c1 < 10, :E_c2 < 20, :maxAE <= 2000, 0 < :log_A1 < 30, 0 < :log_A2 < 20)
end

vars = [:log_A1, :E_c1, :γ, :log_A2, :E_c2, :κ]

# Generate the plot
# plot_all_means_by_ae_bin(sdf; binedges=5:15:200)
```


```{julia}
using CategoricalArrays
using Measurements

# Fix for AlgebraOfGraphics
# Base.typemin(x::Type{Measurement{Float64}}) = -Inf
# Base.typemax(x::Type{Measurement{Float64}}) = Inf

mean_std(x) = mean(x) ± std(x)

let binedges = 5:15:200
    tdf = @chain sdf begin
        @transform(:maxAE_bin = cut(:maxAE, binedges; extend=missing))
        @groupby(:maxAE_bin)
        combine(vars .=> mean_std, :maxAE => mean; renamecols=false)
        dropmissing!
    end

    # https://github.com/MakieOrg/AlgebraOfGraphics.jl/issues/688
    # AoG does not support Errorbars
    # plt = data(tdf) * mapping(:maxAE, [:log_A1, :E_c1, :γ, :log_A2, :E_c2, :κ]) *
    #   (visual(Scatter) + visual(Errorbars, whiskerwidth=8)) * mapping(layout=AoG.dims(1))
    # draw(plt)

    f = Figure()
    x = tdf.maxAE
    ys = vars .=> ["log A1", "E_c (keV)", "γ", "log A2", "E_c2 (keV)", "κ"]
    layouts = [(1, 1), (2, 1), (3, 1), (1, 2), (2, 2), (3, 2)]

    axs = map(layouts, ys) do (i, j), (var, ylabel)
        ax = Axis(f[i, j]; ylabel)
        y = tdf[!, var]
        scatter!(ax, x, y)
        errorbars!(ax, x, y, whiskerwidth=8)
        i != 3 && hidexdecorations!(ax)
        ax
    end
    f
end
```

### MLT, maxAE space

```{julia}
mlt_fmt(from, to, i; leftclosed, rightclosed) = string(Int(from + (to - from) / 2))
mlt_levels = ["13", "15", "17", "19", "21", "23", "1", "3", "5", "7", "9", "11"]

tdf = let binedges_ae = [0, 100, 300], binedges_mlt = 0:2:24
    @chain sdf begin
        @transform(
            :maxAE_bin = cut(:maxAE, binedges_ae; extend=true),
            :mlt_bin = cut(:elfin_mlt, binedges_mlt; extend=missing, labels=mlt_fmt),
        )
        @groupby(:mlt_bin, :maxAE_bin)
        combine(vars .=> mean, renamecols=false)
        dropmissing!
    end
end

# Reorder MLT levels: 12→24, then 0→12
levels!(tdf.mlt_bin, mlt_levels)

#  plot in such a way, that it will be MLT from 12 to 24, and then from 0 to 12, so 24=0 will be in the middle of figure
f = Figure(; size=(600, 600))
base_plt = data(tdf) * mapping(:mlt_bin => "MLT", :maxAE_bin => "AE") * visual(Heatmap)
layouts = [(1, 1), (2, 1), (3, 1), (1, 2), (2, 2), (3, 2)]
foreach(layouts, vars) do (i, j), var
    gl = GridLayout(f[i, j])
    sf = draw!(gl[2, 1], base_plt * mapping(var))
    colorbar!(gl[1, 1], sf; vertical=:false)
    i != 3 && hidexdecorations!(sf[1].axis)
    j != 1 && hideydecorations!(sf[1].axis)
    rowgap!(gl, 4)
end
f
```

### mlt, mlat space, separately for three MaxAE ranges

```{julia}
# Prepare data with MLT and MLAT binning
mlat_binedges = 60:1:80
mlt_binedges = 0:2:24
ae_binedges = [0, 100, 300]

fmt(from, to, i; leftclosed, rightclosed) = string(from + (to - from) / 2)

tdf_spatial = let
    @chain sdf begin
        @transform(
            :maxAE_bin = cut(:maxAE, ae_binedges; extend=true),
            :mlt_bin = cut(:elfin_mlt, mlt_binedges; extend=missing, labels=mlt_fmt),
            :mlat_bin = cut(abs.(:mlat), mlat_binedges; extend=missing, labels=fmt),
        )
        @groupby(:mlt_bin, :mlat_bin, :maxAE_bin)
        combine(vars .=> mean, renamecols=false)
        dropmissing!
    end
end

# Reorder MLT levels: 12→24, then 0→12
levels!(tdf_spatial.mlt_bin, mlt_levels)

# Create figure with 3 rows (one per AE range) and 6 columns (one per variable)
f = Figure(; size=(1800, 900))

ae_bins = unique(tdf_spatial.maxAE_bin)

_mlat(s) = parse(Float64, String(s))

colorranges = Dict(
    :log_A1 => (9, 17),
    :E_c1 => (0, 5),
    :γ => (-3.6, 1),
    :log_A2 => (6, 11),
    :E_c2 => (0, 5),
    :κ => (2, 8),
)

# Plot each variable for each AE range
for (col_idx, var) in enumerate(vars)
    colorrange = colorranges[var]
    for (row_idx, ae_bin) in enumerate(ae_bins)
        tdf_subset = @rsubset(tdf_spatial, :maxAE_bin == ae_bin)
        values = tdf_subset[!, var]
        quantiles = quantile(values, [0.01, 0.1, 0.5, 0.9, 0.95, 0.99])
        @info quantiles var
        ax = Axis(f[row_idx, col_idx], xlabel="MLT", ylabel="MLAT")
        # Create heatmap
        x = tdf_subset.mlt_bin
        y = tdf_subset.mlat_bin
        mlt_indices = levelcode.(x)
        mlat_indices = _mlat.(y)
        hm = heatmap!(ax, mlt_indices, mlat_indices, values; colorrange)

        # Customize x-axis ticks for MLT
        ax.xticks = (1:length(mlt_levels), String.(CategoricalArrays.levels(x)))
        # Add colorbar
        row_idx == 1 && Colorbar(f[row_idx-1, col_idx], hm, label=string(var), vertical=false)
        # Add AE range label on the left
        col_idx == 1 && Label(f[row_idx, 0], string(ae_bin), rotation=π / 2, tellheight=false)

        row_idx != length(ae_bins) && hidexdecorations!(ax)
        col_idx != 1 && hideydecorations!(ax)
    end

    # plt = data(tdf_spatial) * mapping(:mlt_bin, :mlat_bin, var) * visual(Heatmap) * mapping(row=:maxAE_bin)
end
f
```

### Fitting of probability distributions

#### Empirical pdf for `log_A1`

```{julia}
using StatsBase
using FHist
includet("../src/statmodel.jl")
# logA1_empirical = empirical_conditional_density(sdf, :log_A1)
var_edges = map(vars) do var
    edge_min, edge_max = quantile(sdf[!, var], [0.01, 0.99])
    range(edge_min, edge_max; length=31)
end

_maximum(h) = maximum(h.weights)
_maximum(h::Hist1D) = maximum(h.bincounts)

hist_funcs = HistFunc.(var_edges)

tdf = let mlat_binedges = 49:2:81
    @chain sdf begin
        @transform(
            :maxAE_bin = cut(:maxAE, ae_binedges; extend=true),
            :mlt_bin = cut(:elfin_mlt, mlt_binedges; extend=missing, labels=mlt_fmt),
            :mlat_bin = cut(abs.(:mlat), mlat_binedges; extend=missing, labels=fmt),
        )
        @groupby(:mlt_bin, :mlat_bin, :maxAE_bin)
        combine(vars .=> hist_funcs, renamecols=false)
        dropmissing!
    end
end
# ae_levels = levels(tdf.maxAE_bin)
mlt_levels = levels(tdf.mlt_bin)
```

#### Visualizing the empirical pdf

```{julia}
f = Figure(size=(1200, 900))

mlt_idxs = 1:2:12

ssdf = @chain tdf begin
    @groupby(:mlt_bin, :mlat_bin)
    combine(vars .=> sum; renamecols=false)
end

foreach(enumerate(vars)) do (i, var)
    # emp = empirical_conditional_density(sdf, var)
    xlabel = string(var)
    hists = ssdf[!, var]
    limits = (0, quantile(_maximum.(hists), 0.95))
    idx = 1
    for (key, subdf) in pairs(@groupby(ssdf, :mlt_bin)[mlt_idxs])
        matrix_data = extract_matrix(subdf, var)
        ax = Axis(f[idx, i]; xlabel, ylabel="|MLAT| (deg)")
        heatmap!(ax, matrix_data; colorrange=limits)
        hists = subdf[!, var]
        mlats = _mlat.(subdf.mlat_bin)
        means = mean.(hists)
        stds = std.(hists)
        lines!(ax, means, mlats, color=:white, linewidth=2)
        lines!(ax, means .+ stds, mlats, color=:white, linewidth=1.5, linestyle=:dash)
        lines!(ax, means .- stds, mlats, color=:white, linewidth=1.5, linestyle=:dash)
        ylims!(ax, (49, 81))
        idx != length(mlt_idxs) && hidexdecorations!(ax)
        i != 1 && hideydecorations!(ax)
        i == 6 && Label(f[idx, i+1], "MLT = $(key.mlt_bin)", rotation=π / 2, tellheight=false)
        idx += 1
    end
    Colorbar(f[0, i]; limits, label="pdf", vertical=false)
end

easy_save("empirical_pdf")
f
```

#### Parametric pdf model conditioned on (MLAT, MLT)

Fitted a cyclic linear model for the conditional mean and log-variance plus a Normal pdf evaluator, then compared model vs empirical densities with RMSE/KL metrics and slice-by-slice line plots.

- The design matrix X includes a constant, |MLAT|, |MLAT|^2, and diurnal harmonics cos(θ), sin(θ) plus their interactions with |MLAT|, where θ = 2π·MLT/24. Solving X \ log_A1 gives β coefficients that predict the conditional mean μ(mlat, mlt).
    - Mean surface: with θ = 2π·(MLT mod 24)/24 and m = |MLAT|, the model sets $μ(m, θ) = β₀ + β₁ m + β₂ m² + β₃ cos θ + β₄ sin θ + β₅ m cos θ + β₆ m sin θ$. The coefficients β are found by least squares: β = argmin‖Xβ - log_A1‖², where the rows of X contain the seven basis functions above.
- Residuals from that mean fit are used to model heteroscedasticity. Another matrix Z (constant, |MLAT|, |MLAT|^2, cos, sin) regresses log(residual^2 + ε) to estimate a log-variance surface γ, keeping the variance positive via the exponential transform.
    - Variance surface: residuals r = log_A1 - μ̂ are used to fit $log σ²(m, θ) = γ₀ + γ₁ m + γ₂ m² + γ₃ cos θ + γ₄ sin θ$, with γ estimated via least squares on the features matrix Z. The model enforces positivity by taking $σ(m, θ) = √(exp(log σ²))$.
- Given μ and σ derived from β and γ, the code assumes a Gaussian conditional density: `pdf_logA1_model(P, mlat, mlt)` evaluates the Normal pdf with those parameter
    - Conditional pdf (notebooks/stats.qmd:341–353): assuming log_A1 | m, θ ∼ Normal(μ(m, θ), σ²(m, θ)), the fitted density evaluates as $pdf(P | m, θ) = (1 / (σ √(2π))) · exp[ -½ ((P - μ)/σ)² ]$.

```{julia}
using LinearAlgebra

# 2π * :elfin_mlt / 24

emp = logA1_empirical
emp.df.angle .= @. 2π * emp.df.elfin_mlt / 24
θ = emp.df.angle
abs_mlat_vals = emp.df.abs_mlat

X = hcat(
    ones(size(emp.df, 1)),
    abs_mlat_vals,
    abs_mlat_vals .^ 2,
    cos.(θ),
    sin.(θ),
    abs_mlat_vals .* cos.(θ),
    abs_mlat_vals .* sin.(θ),
)
β_logA1 = X \ emp.df.log_A1
μ_hat = X * β_logA1
residuals = emp.df.log_A1 .- μ_hat

Z = hcat(
    ones(size(emp.df, 1)),
    abs_mlat_vals,
    abs_mlat_vals .^ 2,
    cos.(θ),
    sin.(θ),
)
γ_logA1 = Z \ log.(residuals .^ 2 .+ 1e-6)

predict_logA1(mlat, mlt) = begin
    abs_mlat = abs(mlat)
    φ = 2π * mod(mlt, 24) / 24
    cosφ, sinφ = cos(φ), sin(φ)
    μ = dot(β_logA1, (1.0, abs_mlat, abs_mlat^2, cosφ, sinφ, abs_mlat * cosφ, abs_mlat * sinφ))
    logσ2 = dot(γ_logA1, (1.0, abs_mlat, abs_mlat^2, cosφ, sinφ))
    σ = sqrt(exp(logσ2))
    σ = max(σ, 1e-3)
    return μ, σ
end

pdf_logA1_model(P, mlat, mlt) = begin
    μ, σ = predict_logA1(mlat, mlt)
    coeff = 1 / (σ * sqrt(2π))
    expo = -0.5 * ((P - μ) / σ)^2
    return coeff * exp(expo)
end

model_density = similar(emp.cond_density)
@views for j in axes(model_density, 2), k in axes(model_density, 3)
    mlat = emp.mlat_centers[j]
    mlt = emp.mlt_centers[k]
    model_density[:, j, k] .= pdf_logA1_model.(emp.p_centers, Ref(mlat), Ref(mlt))
end

logA1_model = (; β_logA1, γ_logA1, model_density, predict_logA1, pdf_logA1_model)
logA1_model
```

#### Model evaluation

```{julia}
emp = logA1_empirical
model = logA1_model

widths_P = emp.widths_P
diff_density = model.model_density .- emp.cond_density
rmse = sqrt(mean(diff_density .^ 2))
mae = mean(abs.(diff_density))

eps = 1e-9
kl = Matrix{Float64}(undef, length(emp.mlat_centers), length(emp.mlt_centers))
fill!(kl, NaN)
@views for j in axes(emp.cond_density, 2), k in axes(emp.cond_density, 3)
    p = emp.cond_density[:, j, k]
    q = model.model_density[:, j, k]
    mask = p .> 0
    if any(mask)
        kl[j, k] = sum(p[mask] .* (log.(p[mask] .+ eps) .- log.(q[mask] .+ eps)) .* widths_P[mask])
    end
end

println("RMSE across pdf grid = $(round(rmse, digits=4))")
println("Mean absolute difference = $(round(mae, digits=4))")
println("Median KL divergence (per bin) = $(round(median(skipmissing(vec(kl))), digits=4))")

comparison_mlat = [60.0, 65.0, 70.0]
comparison_mlt = [0.0, 12.0, 18.0]

index_of(values, target) = findmin(abs.(values .- target))[2]

f = Figure(size=(900, 720))
for (i, mlat_target) in enumerate(comparison_mlat)
    mlat_idx = index_of(emp.mlat_centers, mlat_target)
    for (j, mlt_target) in enumerate(comparison_mlt)
        mlt_idx = index_of(emp.mlt_centers, mlt_target)
        ax = Axis(
            f[i, j];
            title="|MLAT| ~ $(round(emp.mlat_centers[mlat_idx], digits=1)) deg, MLT ~ $(round(emp.mlt_centers[mlt_idx], digits=1)) h",
            xlabel="log10(A1)",
            ylabel=i == length(comparison_mlat) ? "pdf" : "",
            yscale=log10
        )
        empirical = emp.cond_density[:, mlat_idx, mlt_idx]
        modeled = model.model_density[:, mlat_idx, mlt_idx]
        lines_emp = lines!(ax, emp.p_centers, empirical; color=:steelblue, linewidth=2)
        lines_mod = lines!(ax, emp.p_centers, modeled; color=:orange, linestyle=:dash, linewidth=2)
        ylims!(ax, (1e-6, 1))
        i != length(comparison_mlat) && hidexdecorations!(ax)
        j != 1 && hideydecorations!(ax)
        if i == 1 && j == 1
            axislegend(ax, [lines_emp, lines_mod], ["Empirical", "Model"]; position=:rt)
        end
    end
end
f
```




### Joint probability distributions

Probability distributions of observations in (Mlat, Ec) and (Mlat, gamma) spaces?

```{julia}
includet("../src/statplot.jl")
using PairPlots, AlgebraOfGraphics
using StatsBase
const AoG = AlgebraOfGraphics

E_c1(model) = E_c(m1_len(model))
E_c2(model) = E_c(m2_len(model))

# plot_parameter_distributions_aog(df; normalization=:pdf)
# plot_parameter_distributions_aog(df; normalization=:column)

# plot_parameter_distributions_aog(df, :mlat; normalization=:column)
plot_parameter_distributions_aog(dropmissing(df), :maxAE; normalization=:pdf, x_binedges=(0:20:400))
# plot_parameter_distributions_aog(dropmissing(df), :maxAE; normalization=:column, x_binedges=(0:20:1000))

```

```{julia}
# Use PairPlots for comprehensive parameter analysis
function plot_parameter_pairplots(df)
    # Create analysis DataFrame with all relevant parameters
    plot_df = DataFrame(
        mlat=df.mlat,
        E_c=E_c.(m1_len.(df.model)),
        γ=γ_len.(m1_len.(df.model)),
        κ=κ_len.(m2_len.(df.model)),
        success=df.success,
        Δmlt=df.Δmlt
    )

    # Filter for successful fits
    successful_df = @subset(plot_df, :success)

    if nrow(successful_df) == 0
        println("No successful fits found for plotting")
        return nothing
    end

    # Create comprehensive pair plot with all parameters
    return pairplot(successful_df[:, [:mlat, :E_c, :γ, :κ, :Δmlt]])
end

# Plot comprehensive pairwise analysis
plot_parameter_pairplots(df)
```

```{julia}
# Advanced AlgebraOfGraphics visualization with faceting and grouping
function plot_advanced_parameter_analysis(df)
    # Create comprehensive analysis DataFrame
    plot_df = DataFrame(
        mlat=df.mlat,
        E_c=E_c.(m1_len.(df.model)),
        γ=γ_len.(m1_len.(df.model)),
        κ=κ_len.(m2_len.(df.model)),
        success=df.success,
        Δmlt=df.Δmlt,
        id=df.id,
        # Create MLAT bins for grouping
        mlat_bin=cut(df.mlat, 5, labels=["High", "Mid-High", "Mid", "Mid-Low", "Low"])
    )

    # Filter for successful fits
    successful_df = @subset(plot_df, :success)

    if nrow(successful_df) == 0
        println("No successful fits found for plotting")
        return nothing
    end

    # Create multi-faceted analysis
    base = data(successful_df)

    # Density plots with grouping by DMSP satellite ID
    density_analysis = base *
                       mapping(:mlat => "MLAT (degrees)", :E_c => "E_c (keV)",
                           color=:id => nonnumeric, layout=:id => nonnumeric) *
                       (density() * visual(alpha=0.7) +
                        smooth() * visual(linewidth=2))

    # Scatter plot with trend analysis
    scatter_analysis = base *
                       mapping(:γ => "γ", :E_c => "E_c (keV)",
                           color=:mlat_bin => "MLAT Region",
                           markersize=:Δmlt => "ΔMLT") *
                       (visual(Scatter, alpha=0.7) +
                        smooth() * visual(linewidth=1.5))

    # Create figure with multiple panels
    f = Figure(size=(1600, 1000))

    # Panel 1: Density analysis by satellite
    draw!(f[1, :], density_analysis;
        axis=(title="E_c vs MLAT by DMSP Satellite",
            subtitle="Density distributions with trend lines"))

    # Panel 2: Parameter correlation analysis  
    draw!(f[2, 1], scatter_analysis;
        axis=(title="Parameter Correlations",
            subtitle="E_c vs γ colored by MLAT region, sized by ΔMLT"))

    # Panel 3: Distribution summary
    hist_plot = base *
                mapping(:E_c => "E_c (keV)", layout=:mlat_bin => nonnumeric) *
                histogram(bins=15) * visual(alpha=0.8, color=:steelblue)

    draw!(f[2, 2], hist_plot;
        axis=(title="E_c Distribution by MLAT Region",))

    return f
end

# Create advanced multi-panel analysis
plot_advanced_parameter_analysis(df)
```

```{julia}
# Statistical summary of the distributions
function summarize_parameter_distributions(df)
    successful_df = @subset(df, :success)

    println("=== Parameter Distribution Summary ===")
    println("Total successful fits: $(nrow(successful_df))")
    println("Total observations: $(nrow(df))")
    println("Success rate: $(round(nrow(successful_df)/nrow(df)*100, digits=2))%")
    println()

    # MLAT statistics
    println("MLAT Statistics:")
    println("  Range: $(round(minimum(successful_df.mlat), digits=2))° to $(round(maximum(successful_df.mlat), digits=2))°")
    println("  Mean: $(round(mean(successful_df.mlat), digits=2))°")
    println("  Std: $(round(std(successful_df.mlat), digits=2))°")
    println()

    # E_c statistics
    E_c_values = [row.model2.E_c for row in eachrow(successful_df) if haskey(row.model2, :E_c)]
    if !isempty(E_c_values)
        println("E_c Statistics:")
        println("  Range: $(round(minimum(E_c_values), digits=2)) to $(round(maximum(E_c_values), digits=2)) keV")
        println("  Mean: $(round(mean(E_c_values), digits=2)) keV")
        println("  Std: $(round(std(E_c_values), digits=2)) keV")
        println("  Median: $(round(median(E_c_values), digits=2)) keV")
        println()
    end

    # γ statistics
    gamma_values = [row.model1.γ for row in eachrow(successful_df) if haskey(row.model1, :γ)]
    if !isempty(gamma_values)
        println("γ Statistics:")
        println("  Range: $(round(minimum(gamma_values), digits=2)) to $(round(maximum(gamma_values), digits=2))")
        println("  Mean: $(round(mean(gamma_values), digits=2))")
        println("  Std: $(round(std(gamma_values), digits=2))")
        println("  Median: $(round(median(gamma_values), digits=2))")
    end
end

# Print statistical summary
summarize_parameter_distributions(df)
```








## Parameter Statistics and Correlations

```julia
#TODO: update this part
# Calculate parameter statistics and correlations
using Statistics

# Create summary statistics
param_stats = (
    plec_A_mean=mean([p.plec_A for p in param_analysis]),
    plec_A_std=std([p.plec_A for p in param_analysis]),
    plec_γ_mean=mean([p.plec_γ for p in param_analysis]),
    plec_γ_std=std([p.plec_γ for p in param_analysis]),
    plec_E_c_mean=mean([p.plec_E_c for p in param_analysis]),
    plec_E_c_std=std([p.plec_E_c for p in param_analysis]),
    sbpl_A_mean=mean([p.sbpl_A for p in param_analysis]),
    sbpl_A_std=std([p.sbpl_A for p in param_analysis]),
    sbpl_γ1_mean=mean([p.sbpl_γ1 for p in param_analysis]),
    sbpl_γ1_std=std([p.sbpl_γ1 for p in param_analysis]),
    sbpl_γ2_mean=mean([p.sbpl_γ2 for p in param_analysis]),
    sbpl_γ2_std=std([p.sbpl_γ2 for p in param_analysis]),
    sbpl_Eb_mean=mean([p.sbpl_Eb for p in param_analysis]),
    sbpl_Eb_std=std([p.sbpl_Eb for p in param_analysis])
)

@info "Parameter Statistics:" param_stats

# Create correlation plot between key parameters
f_corr = Figure(size=(1200, 900))

# PowerLawExpCutoff γ vs E_c
ax_corr1 = Axis(f_corr[1, 1], xlabel="Power Index γ (PowerLawExpCutoff)",
    ylabel="Cutoff Energy E_c (keV)", yscale=log10,
    title="PowerLawExpCutoff: γ vs E_c")
scatter!(ax_corr1, [p.plec_γ for p in param_analysis],
    [p.plec_E_c for p in param_analysis],
    color=mlats_all, colormap=:viridis, markersize=8)

# PowerLawExpCutoff A vs γ  
ax_corr2 = Axis(f_corr[1, 2], xlabel="Amplitude A (PowerLawExpCutoff)",
    ylabel="Power Index γ", xscale=log10,
    title="PowerLawExpCutoff: A vs γ")
scatter!(ax_corr2, [p.plec_A for p in param_analysis],
    [p.plec_γ for p in param_analysis],
    color=mlats_all, colormap=:viridis, markersize=8)

# SmoothBrokenPowerlaw γ1 vs γ2
ax_corr3 = Axis(f_corr[2, 1], xlabel="Power Index γ₁ (SBPL)",
    ylabel="Power Index γ₂ (SBPL)",
    title="SmoothBrokenPowerlaw: γ₁ vs γ₂")
scatter!(ax_corr3, [p.sbpl_γ1 for p in param_analysis],
    [p.sbpl_γ2 for p in param_analysis],
    color=mlats_all, colormap=:viridis, markersize=8)

# Break energy vs MLAT colored by PowerLawExpCutoff cutoff
ax_corr4 = Axis(f_corr[2, 2], xlabel="MLAT", ylabel="Break Energy Eb (keV)",
    yscale=log10, title="Break Energy vs MLAT")
scatter!(ax_corr4, mlats_all, [p.sbpl_Eb for p in param_analysis],
    color=[p.plec_E_c for p in param_analysis], colormap=:plasma, markersize=8)

# Add colorbars
Colorbar(f_corr[1:2, 3], colormap=:viridis, colorrange=extrema(mlats_all),
    label="MLAT")

f_corr
```
